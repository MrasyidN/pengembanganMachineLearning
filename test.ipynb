{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# introduce tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rasyid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7952 - loss: 0.5808\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8683 - loss: 0.3625\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8826 - loss: 0.3181\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8865 - loss: 0.3022\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.2789\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9008 - loss: 0.2661\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9070 - loss: 0.2480\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9114 - loss: 0.2359\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2312\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.2175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2659a1c2480>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    " \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    " \n",
    "# melakukan definisi\n",
    "model = tf.keras.models.Sequential([\n",
    "    # input layer\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    # hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # output layer\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "                              loss = 'sparse_categorical_crossentropy',\n",
    "                              metrics = ['accuracy'])\n",
    "# maltih model dengan iterasi 10\n",
    "model.fit(x_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pra-pemrosesan Data untuk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data augmentasi kalau tensorflow versi < 2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./225,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    shear_range = 0.2,\n",
    "    fill_mode = 'nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data augmentasi kalau tensorflow versi > 2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "IMG_SIZE = 100\n",
    "\n",
    "resize_andre_scale = tf.keras.Sequential([\n",
    "    layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "    layers.Rescaling(1./255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melakukan berbagai cungsi augmentasi\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tahap terakhir memasukan data augmentasi pada layer sequentials\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "#menambahkan processing image yang telah didefinisikan sebelumnya\n",
    "resize_andre_scale,\n",
    "data_augmentation,\n",
    "\n",
    "layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "layers.MaxPooling2D(),\n",
    "\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pemrosesan data bahasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 1, 'love': 2, 'my': 3, 'cat': 4}\n",
      "[[1, 2, 3, 4]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "sentences = [\"i love my cat\"]\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 300)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(sequences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### menggunakan model untuk melakukan prediksi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4. -3. -2. -1.  0.  1.  2.  3.  4.  5.]\n",
      "[ 5.  6.  7.  8.  9. 10. 11. 12. 13. 14.]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([-4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0], dtype=float)\n",
    "Y = np.array([5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0], dtype=float)\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rasyid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# memilih model NN \n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, input_shape=[1])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Parameter units dari fungsi keras.layers.Dense() adalah jumlah perceptron yang dimiliki oleh layer tersebut. Yang perlu diperhatikan pada model sequential adalah layer pertama dari model tersebut haruslah memiliki parameter input_shape agar model bisa mengenali bentuk input yang akan diprosesnya.\n",
    " - Parameter input_shape menunjukkan bentuk dari setiap elemen input yang akan diterima oleh model. Pada kasus yang kita alami, setiap elemen dari data adalah sebuah bilangan numerik 1 digit sehingga input_shape dapat diisi dengan angka 1. Jika sebuah elemen dari dataset kita berupa gambar yang memiliki dimensi 32*32 piksel, input_shape yang sesuai adalah [32,32].\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - loss: 87.2350\n",
      "Epoch 2/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 81.2057\n",
      "Epoch 3/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 76.2467\n",
      "Epoch 4/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 72.0548\n",
      "Epoch 5/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 68.4205\n",
      "Epoch 6/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 65.1985\n",
      "Epoch 7/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 62.2877\n",
      "Epoch 8/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 59.6175\n",
      "Epoch 9/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 57.1385\n",
      "Epoch 10/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 54.8155\n",
      "Epoch 11/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 52.6236\n",
      "Epoch 12/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 50.5445\n",
      "Epoch 13/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 48.5649\n",
      "Epoch 14/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 46.6748\n",
      "Epoch 15/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 44.8665\n",
      "Epoch 16/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 43.1339\n",
      "Epoch 17/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 41.4721\n",
      "Epoch 18/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 39.8771\n",
      "Epoch 19/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 38.3452\n",
      "Epoch 20/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 36.8734\n",
      "Epoch 21/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 35.4590\n",
      "Epoch 22/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 34.0995\n",
      "Epoch 23/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 32.7925\n",
      "Epoch 24/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 31.5359\n",
      "Epoch 25/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 30.3276\n",
      "Epoch 26/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 29.1657\n",
      "Epoch 27/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 28.0485\n",
      "Epoch 28/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 26.9741\n",
      "Epoch 29/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 25.9409\n",
      "Epoch 30/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 24.9474\n",
      "Epoch 31/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 23.9919\n",
      "Epoch 32/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 23.0730\n",
      "Epoch 33/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 22.1893\n",
      "Epoch 34/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 21.3394\n",
      "Epoch 35/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 20.5222\n",
      "Epoch 36/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 19.7362\n",
      "Epoch 37/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 18.9803\n",
      "Epoch 38/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 18.2534\n",
      "Epoch 39/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 17.5543\n",
      "Epoch 40/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 16.8820\n",
      "Epoch 41/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 16.2354\n",
      "Epoch 42/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 15.6136\n",
      "Epoch 43/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 15.0157\n",
      "Epoch 44/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 14.4406\n",
      "Epoch 45/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 13.8875\n",
      "Epoch 46/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 13.3556\n",
      "Epoch 47/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 12.8441\n",
      "Epoch 48/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 12.3522\n",
      "Epoch 49/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 11.8792\n",
      "Epoch 50/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 11.4242\n",
      "Epoch 51/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 10.9867\n",
      "Epoch 52/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 10.5659\n",
      "Epoch 53/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 10.1612\n",
      "Epoch 54/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 9.7721\n",
      "Epoch 55/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 9.3978\n",
      "Epoch 56/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 9.0379\n",
      "Epoch 57/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 8.6918\n",
      "Epoch 58/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 8.3589\n",
      "Epoch 59/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 8.0387\n",
      "Epoch 60/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 7.7309\n",
      "Epoch 61/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 7.4348\n",
      "Epoch 62/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 7.1500\n",
      "Epoch 63/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 6.8762\n",
      "Epoch 64/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 6.6129\n",
      "Epoch 65/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 6.3596\n",
      "Epoch 66/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 6.1160\n",
      "Epoch 67/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 5.8818\n",
      "Epoch 68/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 5.6565\n",
      "Epoch 69/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 5.4399\n",
      "Epoch 70/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 5.2315\n",
      "Epoch 71/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 5.0312\n",
      "Epoch 72/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 4.8385\n",
      "Epoch 73/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 4.6532\n",
      "Epoch 74/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 4.4750\n",
      "Epoch 75/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 4.3036\n",
      "Epoch 76/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 4.1388\n",
      "Epoch 77/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 3.9803\n",
      "Epoch 78/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.8278\n",
      "Epoch 79/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.6812\n",
      "Epoch 80/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 3.5402\n",
      "Epoch 81/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 3.4047\n",
      "Epoch 82/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.2743\n",
      "Epoch 83/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.1489\n",
      "Epoch 84/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 3.0283\n",
      "Epoch 85/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 2.9123\n",
      "Epoch 86/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 2.8007\n",
      "Epoch 87/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 2.6935\n",
      "Epoch 88/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.5903\n",
      "Epoch 89/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 2.4911\n",
      "Epoch 90/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 2.3957\n",
      "Epoch 91/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 2.3040\n",
      "Epoch 92/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 2.2157\n",
      "Epoch 93/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 2.1309\n",
      "Epoch 94/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 2.0493\n",
      "Epoch 95/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.9708\n",
      "Epoch 96/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.8953\n",
      "Epoch 97/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.8227\n",
      "Epoch 98/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 1.7529\n",
      "Epoch 99/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.6858\n",
      "Epoch 100/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 1.6212\n",
      "Epoch 101/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.5591\n",
      "Epoch 102/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.4994\n",
      "Epoch 103/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.4420\n",
      "Epoch 104/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.3867\n",
      "Epoch 105/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 1.3336\n",
      "Epoch 106/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 1.2826\n",
      "Epoch 107/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.2334\n",
      "Epoch 108/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.1862\n",
      "Epoch 109/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.1408\n",
      "Epoch 110/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.0971\n",
      "Epoch 111/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.0551\n",
      "Epoch 112/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.0147\n",
      "Epoch 113/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.9758\n",
      "Epoch 114/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.9384\n",
      "Epoch 115/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.9025\n",
      "Epoch 116/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.8679\n",
      "Epoch 117/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.8347\n",
      "Epoch 118/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.8027\n",
      "Epoch 119/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.7720\n",
      "Epoch 120/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.7424\n",
      "Epoch 121/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.7140\n",
      "Epoch 122/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.6866\n",
      "Epoch 123/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.6603\n",
      "Epoch 124/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.6350\n",
      "Epoch 125/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.6107\n",
      "Epoch 126/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.5873\n",
      "Epoch 127/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.5648\n",
      "Epoch 128/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.5432\n",
      "Epoch 129/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.5224\n",
      "Epoch 130/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.5024\n",
      "Epoch 131/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.4832\n",
      "Epoch 132/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4646\n",
      "Epoch 133/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.4469\n",
      "Epoch 134/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4297\n",
      "Epoch 135/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.4133\n",
      "Epoch 136/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.3975\n",
      "Epoch 137/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3822\n",
      "Epoch 138/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3676\n",
      "Epoch 139/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.3535\n",
      "Epoch 140/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3400\n",
      "Epoch 141/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3270\n",
      "Epoch 142/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3144\n",
      "Epoch 143/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3024\n",
      "Epoch 144/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2908\n",
      "Epoch 145/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2797\n",
      "Epoch 146/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2690\n",
      "Epoch 147/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.2587\n",
      "Epoch 148/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2488\n",
      "Epoch 149/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2392\n",
      "Epoch 150/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.2301\n",
      "Epoch 151/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2213\n",
      "Epoch 152/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2128\n",
      "Epoch 153/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2046\n",
      "Epoch 154/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1968\n",
      "Epoch 155/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1893\n",
      "Epoch 156/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1820\n",
      "Epoch 157/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1750\n",
      "Epoch 158/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1683\n",
      "Epoch 159/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1619\n",
      "Epoch 160/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1557\n",
      "Epoch 161/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1497\n",
      "Epoch 162/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1440\n",
      "Epoch 163/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1385\n",
      "Epoch 164/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1332\n",
      "Epoch 165/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1281\n",
      "Epoch 166/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.1232\n",
      "Epoch 167/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1184\n",
      "Epoch 168/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.1139\n",
      "Epoch 169/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.1096\n",
      "Epoch 170/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1054\n",
      "Epoch 171/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1013\n",
      "Epoch 172/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0974\n",
      "Epoch 173/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0937\n",
      "Epoch 174/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0901\n",
      "Epoch 175/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0867\n",
      "Epoch 176/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0833\n",
      "Epoch 177/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0802\n",
      "Epoch 178/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0771\n",
      "Epoch 179/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0741\n",
      "Epoch 180/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0713\n",
      "Epoch 181/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0686\n",
      "Epoch 182/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0659\n",
      "Epoch 183/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0634\n",
      "Epoch 184/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0610\n",
      "Epoch 185/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0586\n",
      "Epoch 186/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0564\n",
      "Epoch 187/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0542\n",
      "Epoch 188/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0522\n",
      "Epoch 189/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0502\n",
      "Epoch 190/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0482\n",
      "Epoch 191/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0464\n",
      "Epoch 192/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0446\n",
      "Epoch 193/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0429\n",
      "Epoch 194/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0413\n",
      "Epoch 195/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0397\n",
      "Epoch 196/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0382\n",
      "Epoch 197/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0367\n",
      "Epoch 198/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0353\n",
      "Epoch 199/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0339\n",
      "Epoch 200/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0326\n",
      "Epoch 201/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0314\n",
      "Epoch 202/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0302\n",
      "Epoch 203/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0290\n",
      "Epoch 204/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0279\n",
      "Epoch 205/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0269\n",
      "Epoch 206/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0258\n",
      "Epoch 207/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0248\n",
      "Epoch 208/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0239\n",
      "Epoch 209/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0230\n",
      "Epoch 210/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0221\n",
      "Epoch 211/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0212\n",
      "Epoch 212/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0204\n",
      "Epoch 213/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0197\n",
      "Epoch 214/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0189\n",
      "Epoch 215/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0182\n",
      "Epoch 216/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0175\n",
      "Epoch 217/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0168\n",
      "Epoch 218/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0162\n",
      "Epoch 219/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0155\n",
      "Epoch 220/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0150\n",
      "Epoch 221/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0144\n",
      "Epoch 222/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0138\n",
      "Epoch 223/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0133\n",
      "Epoch 224/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0128\n",
      "Epoch 225/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0123\n",
      "Epoch 226/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0118\n",
      "Epoch 227/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0114\n",
      "Epoch 228/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0109\n",
      "Epoch 229/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0105\n",
      "Epoch 230/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0101\n",
      "Epoch 231/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0097\n",
      "Epoch 232/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0094\n",
      "Epoch 233/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0090\n",
      "Epoch 234/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0087\n",
      "Epoch 235/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0083\n",
      "Epoch 236/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0080\n",
      "Epoch 237/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0077\n",
      "Epoch 238/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0074\n",
      "Epoch 239/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0071\n",
      "Epoch 240/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0068\n",
      "Epoch 241/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0066\n",
      "Epoch 242/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0063\n",
      "Epoch 243/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0061\n",
      "Epoch 244/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0059\n",
      "Epoch 245/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0056\n",
      "Epoch 246/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0054\n",
      "Epoch 247/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0052\n",
      "Epoch 248/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0050\n",
      "Epoch 249/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0048\n",
      "Epoch 250/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0046\n",
      "Epoch 251/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0045\n",
      "Epoch 252/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0043\n",
      "Epoch 253/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0041\n",
      "Epoch 254/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0040\n",
      "Epoch 255/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0038\n",
      "Epoch 256/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0037\n",
      "Epoch 257/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0035\n",
      "Epoch 258/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0034\n",
      "Epoch 259/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0033\n",
      "Epoch 260/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0031\n",
      "Epoch 261/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0030\n",
      "Epoch 262/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0029\n",
      "Epoch 263/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0028\n",
      "Epoch 264/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0027\n",
      "Epoch 265/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0026\n",
      "Epoch 266/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0025\n",
      "Epoch 267/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0024\n",
      "Epoch 268/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0023\n",
      "Epoch 269/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0022\n",
      "Epoch 270/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0021\n",
      "Epoch 271/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0020\n",
      "Epoch 272/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0020\n",
      "Epoch 273/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0019\n",
      "Epoch 274/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0018\n",
      "Epoch 275/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0017\n",
      "Epoch 276/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0017\n",
      "Epoch 277/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0016\n",
      "Epoch 278/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0016\n",
      "Epoch 279/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0015\n",
      "Epoch 280/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0014\n",
      "Epoch 281/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0014\n",
      "Epoch 282/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0013\n",
      "Epoch 283/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0013\n",
      "Epoch 284/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0012\n",
      "Epoch 285/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0012\n",
      "Epoch 286/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0011\n",
      "Epoch 287/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0011\n",
      "Epoch 288/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0011\n",
      "Epoch 289/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0010\n",
      "Epoch 290/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 9.7149e-04\n",
      "Epoch 291/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 9.3430e-04\n",
      "Epoch 292/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 8.9851e-04\n",
      "Epoch 293/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 8.6408e-04\n",
      "Epoch 294/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 8.3098e-04\n",
      "Epoch 295/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 7.9916e-04\n",
      "Epoch 296/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 7.6854e-04\n",
      "Epoch 297/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 7.3912e-04\n",
      "Epoch 298/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 7.1084e-04\n",
      "Epoch 299/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 6.8359e-04\n",
      "Epoch 300/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 6.5741e-04\n",
      "Epoch 301/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 6.3222e-04\n",
      "Epoch 302/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 6.0801e-04\n",
      "Epoch 303/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.8475e-04\n",
      "Epoch 304/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 5.6233e-04\n",
      "Epoch 305/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 5.4079e-04\n",
      "Epoch 306/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 5.2010e-04\n",
      "Epoch 307/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 5.0019e-04\n",
      "Epoch 308/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 4.8104e-04\n",
      "Epoch 309/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 4.6263e-04\n",
      "Epoch 310/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 4.4489e-04\n",
      "Epoch 311/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 4.2785e-04\n",
      "Epoch 312/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 4.1145e-04\n",
      "Epoch 313/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3.9570e-04\n",
      "Epoch 314/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.8056e-04\n",
      "Epoch 315/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.6600e-04\n",
      "Epoch 316/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.5197e-04\n",
      "Epoch 317/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 3.3849e-04\n",
      "Epoch 318/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 3.2551e-04\n",
      "Epoch 319/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.1305e-04\n",
      "Epoch 320/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 3.0106e-04\n",
      "Epoch 321/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 2.8953e-04\n",
      "Epoch 322/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 2.7845e-04\n",
      "Epoch 323/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 2.6779e-04\n",
      "Epoch 324/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 2.5753e-04\n",
      "Epoch 325/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.4767e-04\n",
      "Epoch 326/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 2.3818e-04\n",
      "Epoch 327/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.2905e-04\n",
      "Epoch 328/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.2028e-04\n",
      "Epoch 329/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 2.1186e-04\n",
      "Epoch 330/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 2.0375e-04\n",
      "Epoch 331/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.9594e-04\n",
      "Epoch 332/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.8844e-04\n",
      "Epoch 333/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.8124e-04\n",
      "Epoch 334/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 1.7429e-04\n",
      "Epoch 335/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.6761e-04\n",
      "Epoch 336/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.6120e-04\n",
      "Epoch 337/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.5503e-04\n",
      "Epoch 338/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 1.4910e-04\n",
      "Epoch 339/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.4339e-04\n",
      "Epoch 340/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.3791e-04\n",
      "Epoch 341/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.3262e-04\n",
      "Epoch 342/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.2754e-04\n",
      "Epoch 343/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.2266e-04\n",
      "Epoch 344/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.1796e-04\n",
      "Epoch 345/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.1346e-04\n",
      "Epoch 346/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.0911e-04\n",
      "Epoch 347/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.0493e-04\n",
      "Epoch 348/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.0091e-04\n",
      "Epoch 349/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 9.7037e-05\n",
      "Epoch 350/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 9.3315e-05\n",
      "Epoch 351/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 8.9737e-05\n",
      "Epoch 352/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 8.6297e-05\n",
      "Epoch 353/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 8.2996e-05\n",
      "Epoch 354/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 7.9824e-05\n",
      "Epoch 355/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 7.6765e-05\n",
      "Epoch 356/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 7.3830e-05\n",
      "Epoch 357/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 7.0998e-05\n",
      "Epoch 358/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 6.8286e-05\n",
      "Epoch 359/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 6.5670e-05\n",
      "Epoch 360/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 6.3152e-05\n",
      "Epoch 361/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 6.0726e-05\n",
      "Epoch 362/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 5.8404e-05\n",
      "Epoch 363/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 5.6171e-05\n",
      "Epoch 364/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 5.4023e-05\n",
      "Epoch 365/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 5.1957e-05\n",
      "Epoch 366/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 4.9971e-05\n",
      "Epoch 367/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 4.8063e-05\n",
      "Epoch 368/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 4.6218e-05\n",
      "Epoch 369/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 4.4445e-05\n",
      "Epoch 370/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 4.2745e-05\n",
      "Epoch 371/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 4.1102e-05\n",
      "Epoch 372/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3.9528e-05\n",
      "Epoch 373/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 3.8019e-05\n",
      "Epoch 374/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 3.6561e-05\n",
      "Epoch 375/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 3.5164e-05\n",
      "Epoch 376/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 3.3818e-05\n",
      "Epoch 377/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.2519e-05\n",
      "Epoch 378/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 3.1277e-05\n",
      "Epoch 379/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.0080e-05\n",
      "Epoch 380/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.8928e-05\n",
      "Epoch 381/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2.7816e-05\n",
      "Epoch 382/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 2.6745e-05\n",
      "Epoch 383/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 2.5724e-05\n",
      "Epoch 384/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 2.4743e-05\n",
      "Epoch 385/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 2.3798e-05\n",
      "Epoch 386/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 2.2892e-05\n",
      "Epoch 387/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 2.2019e-05\n",
      "Epoch 388/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 2.1171e-05\n",
      "Epoch 389/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 2.0357e-05\n",
      "Epoch 390/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1.9576e-05\n",
      "Epoch 391/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.8826e-05\n",
      "Epoch 392/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.8108e-05\n",
      "Epoch 393/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.7410e-05\n",
      "Epoch 394/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.6743e-05\n",
      "Epoch 395/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 1.6103e-05\n",
      "Epoch 396/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.5484e-05\n",
      "Epoch 397/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.4890e-05\n",
      "Epoch 398/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.4322e-05\n",
      "Epoch 399/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.3772e-05\n",
      "Epoch 400/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.3248e-05\n",
      "Epoch 401/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.2740e-05\n",
      "Epoch 402/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.2255e-05\n",
      "Epoch 403/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.1786e-05\n",
      "Epoch 404/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.1331e-05\n",
      "Epoch 405/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.0900e-05\n",
      "Epoch 406/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 1.0481e-05\n",
      "Epoch 407/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.0078e-05\n",
      "Epoch 408/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 9.6944e-06\n",
      "Epoch 409/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 9.3224e-06\n",
      "Epoch 410/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 8.9646e-06\n",
      "Epoch 411/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 8.6194e-06\n",
      "Epoch 412/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 8.2915e-06\n",
      "Epoch 413/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 7.9756e-06\n",
      "Epoch 414/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 7.6705e-06\n",
      "Epoch 415/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 7.3761e-06\n",
      "Epoch 416/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 7.0933e-06\n",
      "Epoch 417/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 6.8211e-06\n",
      "Epoch 418/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 6.5580e-06\n",
      "Epoch 419/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 6.3056e-06\n",
      "Epoch 420/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 6.0620e-06\n",
      "Epoch 421/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 5.8286e-06\n",
      "Epoch 422/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.6041e-06\n",
      "Epoch 423/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 5.3882e-06\n",
      "Epoch 424/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 5.1810e-06\n",
      "Epoch 425/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 4.9818e-06\n",
      "Epoch 426/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 4.7903e-06\n",
      "Epoch 427/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 4.6073e-06\n",
      "Epoch 428/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 4.4312e-06\n",
      "Epoch 429/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 4.2634e-06\n",
      "Epoch 430/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 4.1015e-06\n",
      "Epoch 431/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.9431e-06\n",
      "Epoch 432/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 3.7915e-06\n",
      "Epoch 433/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3.6468e-06\n",
      "Epoch 434/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 3.5080e-06\n",
      "Epoch 435/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3.3719e-06\n",
      "Epoch 436/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 3.2425e-06\n",
      "Epoch 437/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 3.1183e-06\n",
      "Epoch 438/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 3.0001e-06\n",
      "Epoch 439/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 2.8838e-06\n",
      "Epoch 440/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 2.7732e-06\n",
      "Epoch 441/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 2.6678e-06\n",
      "Epoch 442/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 2.5643e-06\n",
      "Epoch 443/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 2.4659e-06\n",
      "Epoch 444/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 2.3726e-06\n",
      "Epoch 445/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.2805e-06\n",
      "Epoch 446/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.1936e-06\n",
      "Epoch 447/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 2.1109e-06\n",
      "Epoch 448/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 2.0298e-06\n",
      "Epoch 449/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.9526e-06\n",
      "Epoch 450/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.8773e-06\n",
      "Epoch 451/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.8061e-06\n",
      "Epoch 452/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.7360e-06\n",
      "Epoch 453/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.6697e-06\n",
      "Epoch 454/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 1.6047e-06\n",
      "Epoch 455/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 1.5434e-06\n",
      "Epoch 456/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.4834e-06\n",
      "Epoch 457/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.4269e-06\n",
      "Epoch 458/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.3710e-06\n",
      "Epoch 459/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.3188e-06\n",
      "Epoch 460/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 1.2675e-06\n",
      "Epoch 461/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.2193e-06\n",
      "Epoch 462/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.1722e-06\n",
      "Epoch 463/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.1277e-06\n",
      "Epoch 464/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.0842e-06\n",
      "Epoch 465/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.0433e-06\n",
      "Epoch 466/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.0035e-06\n",
      "Epoch 467/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 9.6461e-07\n",
      "Epoch 468/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 9.2789e-07\n",
      "Epoch 469/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 8.9208e-07\n",
      "Epoch 470/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 8.5856e-07\n",
      "Epoch 471/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 8.2583e-07\n",
      "Epoch 472/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 7.9373e-07\n",
      "Epoch 473/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 7.6376e-07\n",
      "Epoch 474/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 7.3465e-07\n",
      "Epoch 475/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 7.0589e-07\n",
      "Epoch 476/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 6.7926e-07\n",
      "Epoch 477/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 6.5316e-07\n",
      "Epoch 478/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 6.2764e-07\n",
      "Epoch 479/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 6.0397e-07\n",
      "Epoch 480/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 5.8091e-07\n",
      "Epoch 481/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 5.5822e-07\n",
      "Epoch 482/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 5.3723e-07\n",
      "Epoch 483/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 5.1689e-07\n",
      "Epoch 484/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 4.9670e-07\n",
      "Epoch 485/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 4.7714e-07\n",
      "Epoch 486/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 4.5926e-07\n",
      "Epoch 487/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 4.4147e-07\n",
      "Epoch 488/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 4.2403e-07\n",
      "Epoch 489/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 4.0848e-07\n",
      "Epoch 490/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 3.9302e-07\n",
      "Epoch 491/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 3.7771e-07\n",
      "Epoch 492/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 3.6280e-07\n",
      "Epoch 493/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3.4945e-07\n",
      "Epoch 494/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 3.3622e-07\n",
      "Epoch 495/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 3.2325e-07\n",
      "Epoch 496/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 3.1062e-07\n",
      "Epoch 497/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 2.9909e-07\n",
      "Epoch 498/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.8796e-07\n",
      "Epoch 499/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 2.7704e-07\n",
      "Epoch 500/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 2.6616e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e290c8ffe0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impelementasi optimizer dan loss function \n",
    "\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "# pemanggilan fit untuk menyuruh model mempelajari hubungan antara atribut dan label\n",
    "model.fit(X,Y, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12.999623],\n",
       "       [13.999658]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memprediksi model \n",
    "model.predict(np.array([4,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[13.],\n",
       "       [14.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memprediksi model \n",
    "model.predict(np.array([4,5])).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model sekuensial dengan beberapa layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rasyid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=20, input_shape=[1]),\n",
    "    tf.keras.layers.Dense(units=15),\n",
    "    tf.keras.layers.Dense(units=10),\n",
    "    tf.keras.layers.Dense(units=1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat Model untuk Klasifikasi Dua Kelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>diameter</th>\n",
       "      <th>weight</th>\n",
       "      <th>red</th>\n",
       "      <th>green</th>\n",
       "      <th>blue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orange</td>\n",
       "      <td>2.96</td>\n",
       "      <td>86.76</td>\n",
       "      <td>172</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orange</td>\n",
       "      <td>3.91</td>\n",
       "      <td>88.05</td>\n",
       "      <td>166</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orange</td>\n",
       "      <td>4.42</td>\n",
       "      <td>95.17</td>\n",
       "      <td>156</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orange</td>\n",
       "      <td>4.47</td>\n",
       "      <td>95.60</td>\n",
       "      <td>163</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orange</td>\n",
       "      <td>4.48</td>\n",
       "      <td>95.76</td>\n",
       "      <td>161</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  diameter  weight  red  green  blue\n",
       "0  orange      2.96   86.76  172     85     2\n",
       "1  orange      3.91   88.05  166     78     3\n",
       "2  orange      4.42   95.17  156     81     2\n",
       "3  orange      4.47   95.60  163     81     4\n",
       "4  orange      4.48   95.76  161     72     9"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/MrasyidN/dataset/refs/heads/main/Oranges%20vs.%20Grapefruit/citrus.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   name      10000 non-null  object \n",
      " 1   diameter  10000 non-null  float64\n",
      " 2   weight    10000 non-null  float64\n",
      " 3   red       10000 non-null  int64  \n",
      " 4   green     10000 non-null  int64  \n",
      " 5   blue      10000 non-null  int64  \n",
      "dtypes: float64(2), int64(3), object(1)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "orange        5000\n",
       "grapefruit    5000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# karena NN tidak bisa memproses kategori jadi mubah ke numerik\n",
    "\n",
    "# df.name[df.name == 'grapefruit'] = 0\n",
    "# df.name[df.name == 'orange'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  diameter  weight  red  green  blue\n",
      "0        1      2.96   86.76  172     85     2\n",
      "1        1      3.91   88.05  166     78     3\n",
      "2        1      4.42   95.17  156     81     2\n",
      "3        1      4.47   95.60  163     81     4\n",
      "4        1      4.48   95.76  161     72     9\n",
      "...    ...       ...     ...  ...    ...   ...\n",
      "9995     0     15.35  253.89  149     77    20\n",
      "9996     0     15.41  254.67  148     68     7\n",
      "9997     0     15.59  256.50  168     82    20\n",
      "9998     0     15.92  260.14  142     72    11\n",
      "9999     0     16.45  261.51  152     74     2\n",
      "\n",
      "[10000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# bisa juga menggunakan label encoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df['name'] = label_encoder.fit_transform(df['name'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.74025974, 0.63529412, 0.        ],\n",
       "       [0.07042254, 0.00738197, 0.66233766, 0.55294118, 0.01851852],\n",
       "       [0.10822832, 0.04812589, 0.53246753, 0.58823529, 0.        ],\n",
       "       ...,\n",
       "       [0.93624907, 0.97133047, 0.68831169, 0.6       , 0.33333333],\n",
       "       [0.96071164, 0.99216023, 0.35064935, 0.48235294, 0.16666667],\n",
       "       [1.        , 1.        , 0.48051948, 0.50588235, 0.        ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scale = min_max_scaler.fit_transform(X)\n",
    "x_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melakukan pemisahan pada data training dan testgin\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_scale, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5163 - loss: 0.7006\n",
      "Epoch 2/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8604 - loss: 0.6578\n",
      "Epoch 3/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8999 - loss: 0.6155\n",
      "Epoch 4/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9144 - loss: 0.5506\n",
      "Epoch 5/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.4602\n",
      "Epoch 6/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9190 - loss: 0.3627\n",
      "Epoch 7/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9254 - loss: 0.2876\n",
      "Epoch 8/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9192 - loss: 0.2505\n",
      "Epoch 9/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2229\n",
      "Epoch 10/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9238 - loss: 0.2092\n",
      "Epoch 11/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9289 - loss: 0.1971\n",
      "Epoch 12/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9293 - loss: 0.1915\n",
      "Epoch 13/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.1845\n",
      "Epoch 14/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.1839\n",
      "Epoch 15/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.1851\n",
      "Epoch 16/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.1806\n",
      "Epoch 17/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9223 - loss: 0.1877\n",
      "Epoch 18/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9221 - loss: 0.1948\n",
      "Epoch 19/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.1837\n",
      "Epoch 20/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9359 - loss: 0.1705\n",
      "Epoch 21/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9230 - loss: 0.1887\n",
      "Epoch 22/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9253 - loss: 0.1862\n",
      "Epoch 23/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9322 - loss: 0.1717\n",
      "Epoch 24/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.1845\n",
      "Epoch 25/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9278 - loss: 0.1832\n",
      "Epoch 26/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9249 - loss: 0.1860\n",
      "Epoch 27/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9313 - loss: 0.1722\n",
      "Epoch 28/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.1808\n",
      "Epoch 29/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9289 - loss: 0.1765   \n",
      "Epoch 30/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.1801\n",
      "Epoch 31/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.1783\n",
      "Epoch 32/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.1751\n",
      "Epoch 33/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9285 - loss: 0.1812\n",
      "Epoch 34/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9239 - loss: 0.1875\n",
      "Epoch 35/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9305 - loss: 0.1741\n",
      "Epoch 36/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.1770\n",
      "Epoch 37/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9285 - loss: 0.1809\n",
      "Epoch 38/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9255 - loss: 0.1918\n",
      "Epoch 39/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9234 - loss: 0.1865\n",
      "Epoch 40/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9254 - loss: 0.1895\n",
      "Epoch 41/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9244 - loss: 0.1820\n",
      "Epoch 42/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.1813\n",
      "Epoch 43/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.1723\n",
      "Epoch 44/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9281 - loss: 0.1796\n",
      "Epoch 45/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9332 - loss: 0.1699\n",
      "Epoch 46/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.1773\n",
      "Epoch 47/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9277 - loss: 0.1736\n",
      "Epoch 48/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9289 - loss: 0.1783\n",
      "Epoch 49/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9312 - loss: 0.1791\n",
      "Epoch 50/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9295 - loss: 0.1769  \n",
      "Epoch 51/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.1840\n",
      "Epoch 52/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9329 - loss: 0.1716\n",
      "Epoch 53/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9224 - loss: 0.1851\n",
      "Epoch 54/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9302 - loss: 0.1789  \n",
      "Epoch 55/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.1723\n",
      "Epoch 56/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9200 - loss: 0.1859\n",
      "Epoch 57/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9330 - loss: 0.1707\n",
      "Epoch 58/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9225 - loss: 0.1903\n",
      "Epoch 59/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.1798\n",
      "Epoch 60/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9282 - loss: 0.1816\n",
      "Epoch 61/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9253 - loss: 0.1825\n",
      "Epoch 62/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.1720\n",
      "Epoch 63/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.1820\n",
      "Epoch 64/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9238 - loss: 0.1841\n",
      "Epoch 65/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9230 - loss: 0.1819\n",
      "Epoch 66/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9338 - loss: 0.1697\n",
      "Epoch 67/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9235 - loss: 0.1893  \n",
      "Epoch 68/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.1905\n",
      "Epoch 69/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9251 - loss: 0.1823\n",
      "Epoch 70/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.1792  \n",
      "Epoch 71/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9300 - loss: 0.1748\n",
      "Epoch 72/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.1826\n",
      "Epoch 73/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9200 - loss: 0.1913\n",
      "Epoch 74/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9334 - loss: 0.1743\n",
      "Epoch 75/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.1793  \n",
      "Epoch 76/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9255 - loss: 0.1871\n",
      "Epoch 77/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9305 - loss: 0.1722\n",
      "Epoch 78/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9231 - loss: 0.1900\n",
      "Epoch 79/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9228 - loss: 0.1861\n",
      "Epoch 80/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.1758\n",
      "Epoch 81/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.1837  \n",
      "Epoch 82/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9314 - loss: 0.1696  \n",
      "Epoch 83/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.1710\n",
      "Epoch 84/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9244 - loss: 0.1863\n",
      "Epoch 85/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9281 - loss: 0.1785\n",
      "Epoch 86/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.1810  \n",
      "Epoch 87/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9294 - loss: 0.1757  \n",
      "Epoch 88/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9308 - loss: 0.1785\n",
      "Epoch 89/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9251 - loss: 0.1834\n",
      "Epoch 90/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9324 - loss: 0.1731\n",
      "Epoch 91/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9214 - loss: 0.1884\n",
      "Epoch 92/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.1755\n",
      "Epoch 93/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9248 - loss: 0.1852  \n",
      "Epoch 94/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.1776\n",
      "Epoch 95/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9297 - loss: 0.1745\n",
      "Epoch 96/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9328 - loss: 0.1676\n",
      "Epoch 97/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9255 - loss: 0.1818\n",
      "Epoch 98/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9325 - loss: 0.1684  \n",
      "Epoch 99/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9221 - loss: 0.1832\n",
      "Epoch 100/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.1795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e297e9ca10>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# 3 layer dan menggunakan function relu\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(5,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### membuat dan melatih model klasifikasi banyak kelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citrus = pd.read_csv('https://raw.githubusercontent.com/MrasyidN/dataset/refs/heads/main/Iris.csv')\n",
    "df_citrus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuang kolom yang tidak terpakai\n",
    "df_citrus = df_citrus.drop(columns='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "0              1                0               0\n",
       "1              1                0               0\n",
       "2              1                0               0\n",
       "3              1                0               0\n",
       "4              1                0               0\n",
       "..           ...              ...             ...\n",
       "145            0                0               1\n",
       "146            0                0               1\n",
       "147            0                0               1\n",
       "148            0                0               1\n",
       "149            0                0               1\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melakukan one hot encoding dengan get_dummies()\n",
    "\n",
    "category = pd.get_dummies(df_citrus.Species, dtype=int)\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Iris-setosa  \\\n",
       "0            5.1           3.5            1.4           0.2            1   \n",
       "1            4.9           3.0            1.4           0.2            1   \n",
       "2            4.7           3.2            1.3           0.2            1   \n",
       "3            4.6           3.1            1.5           0.2            1   \n",
       "4            5.0           3.6            1.4           0.2            1   \n",
       "\n",
       "   Iris-versicolor  Iris-virginica  \n",
       "0                0               0  \n",
       "1                0               0  \n",
       "2                0               0  \n",
       "3                0               0  \n",
       "4                0               0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melakuakn penggabungan koilom hasil encoding pada yang sudah ada sebeluymnya\n",
    "new_df = pd.concat([df_citrus, category], axis=1)\n",
    "new_df = new_df.drop(columns='Species')\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, ..., 1. , 0. , 0. ],\n",
       "       [4.9, 3. , 1.4, ..., 1. , 0. , 0. ],\n",
       "       [4.7, 3.2, 1.3, ..., 1. , 0. , 0. ],\n",
       "       ...,\n",
       "       [6.5, 3. , 5.2, ..., 0. , 0. , 1. ],\n",
       "       [6.2, 3.4, 5.4, ..., 0. , 0. , 1. ],\n",
       "       [5.9, 3. , 5.1, ..., 0. , 0. , 1. ]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melakuakn konversi df ke bilangan numpy array\n",
    "\n",
    "dataset = new_df.values\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melakukan pemisahan antara variabel independen dan dependen \n",
    "\n",
    "# variabel independen\n",
    "X = dataset[:,0:4]\n",
    "\n",
    "# variabel dependen\n",
    "y = dataset[:,4:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
       "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
       "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
       "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.30555556, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.        ],\n",
       "       [0.        , 0.41666667, 0.01694915, 0.        ],\n",
       "       [0.41666667, 0.83333333, 0.03389831, 0.04166667],\n",
       "       [0.38888889, 1.        , 0.08474576, 0.125     ],\n",
       "       [0.30555556, 0.79166667, 0.05084746, 0.125     ],\n",
       "       [0.22222222, 0.625     , 0.06779661, 0.08333333],\n",
       "       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.08474576, 0.08333333],\n",
       "       [0.30555556, 0.58333333, 0.11864407, 0.04166667],\n",
       "       [0.22222222, 0.70833333, 0.08474576, 0.125     ],\n",
       "       [0.08333333, 0.66666667, 0.        , 0.04166667],\n",
       "       [0.22222222, 0.54166667, 0.11864407, 0.16666667],\n",
       "       [0.13888889, 0.58333333, 0.15254237, 0.04166667],\n",
       "       [0.19444444, 0.41666667, 0.10169492, 0.04166667],\n",
       "       [0.19444444, 0.58333333, 0.10169492, 0.125     ],\n",
       "       [0.25      , 0.625     , 0.08474576, 0.04166667],\n",
       "       [0.25      , 0.58333333, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.45833333, 0.10169492, 0.04166667],\n",
       "       [0.30555556, 0.58333333, 0.08474576, 0.125     ],\n",
       "       [0.25      , 0.875     , 0.08474576, 0.        ],\n",
       "       [0.33333333, 0.91666667, 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.19444444, 0.5       , 0.03389831, 0.04166667],\n",
       "       [0.33333333, 0.625     , 0.05084746, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.02777778, 0.41666667, 0.05084746, 0.04166667],\n",
       "       [0.22222222, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.05084746, 0.08333333],\n",
       "       [0.05555556, 0.125     , 0.05084746, 0.08333333],\n",
       "       [0.02777778, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.10169492, 0.20833333],\n",
       "       [0.22222222, 0.75      , 0.15254237, 0.125     ],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.10169492, 0.04166667],\n",
       "       [0.08333333, 0.5       , 0.06779661, 0.04166667],\n",
       "       [0.27777778, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.54166667, 0.06779661, 0.04166667],\n",
       "       [0.75      , 0.5       , 0.62711864, 0.54166667],\n",
       "       [0.58333333, 0.5       , 0.59322034, 0.58333333],\n",
       "       [0.72222222, 0.45833333, 0.66101695, 0.58333333],\n",
       "       [0.33333333, 0.125     , 0.50847458, 0.5       ],\n",
       "       [0.61111111, 0.33333333, 0.61016949, 0.58333333],\n",
       "       [0.38888889, 0.33333333, 0.59322034, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.62711864, 0.625     ],\n",
       "       [0.16666667, 0.16666667, 0.38983051, 0.375     ],\n",
       "       [0.63888889, 0.375     , 0.61016949, 0.5       ],\n",
       "       [0.25      , 0.29166667, 0.49152542, 0.54166667],\n",
       "       [0.19444444, 0.        , 0.42372881, 0.375     ],\n",
       "       [0.44444444, 0.41666667, 0.54237288, 0.58333333],\n",
       "       [0.47222222, 0.08333333, 0.50847458, 0.375     ],\n",
       "       [0.5       , 0.375     , 0.62711864, 0.54166667],\n",
       "       [0.36111111, 0.375     , 0.44067797, 0.5       ],\n",
       "       [0.66666667, 0.45833333, 0.57627119, 0.54166667],\n",
       "       [0.36111111, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.41666667, 0.29166667, 0.52542373, 0.375     ],\n",
       "       [0.52777778, 0.08333333, 0.59322034, 0.58333333],\n",
       "       [0.36111111, 0.20833333, 0.49152542, 0.41666667],\n",
       "       [0.44444444, 0.5       , 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.33333333, 0.50847458, 0.5       ],\n",
       "       [0.55555556, 0.20833333, 0.66101695, 0.58333333],\n",
       "       [0.5       , 0.33333333, 0.62711864, 0.45833333],\n",
       "       [0.58333333, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.63888889, 0.41666667, 0.57627119, 0.54166667],\n",
       "       [0.69444444, 0.33333333, 0.6440678 , 0.54166667],\n",
       "       [0.66666667, 0.41666667, 0.6779661 , 0.66666667],\n",
       "       [0.47222222, 0.375     , 0.59322034, 0.58333333],\n",
       "       [0.38888889, 0.25      , 0.42372881, 0.375     ],\n",
       "       [0.33333333, 0.16666667, 0.47457627, 0.41666667],\n",
       "       [0.33333333, 0.16666667, 0.45762712, 0.375     ],\n",
       "       [0.41666667, 0.29166667, 0.49152542, 0.45833333],\n",
       "       [0.47222222, 0.29166667, 0.69491525, 0.625     ],\n",
       "       [0.30555556, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.47222222, 0.58333333, 0.59322034, 0.625     ],\n",
       "       [0.66666667, 0.45833333, 0.62711864, 0.58333333],\n",
       "       [0.55555556, 0.125     , 0.57627119, 0.5       ],\n",
       "       [0.36111111, 0.41666667, 0.52542373, 0.5       ],\n",
       "       [0.33333333, 0.20833333, 0.50847458, 0.5       ],\n",
       "       [0.33333333, 0.25      , 0.57627119, 0.45833333],\n",
       "       [0.5       , 0.41666667, 0.61016949, 0.54166667],\n",
       "       [0.41666667, 0.25      , 0.50847458, 0.45833333],\n",
       "       [0.19444444, 0.125     , 0.38983051, 0.375     ],\n",
       "       [0.36111111, 0.29166667, 0.54237288, 0.5       ],\n",
       "       [0.38888889, 0.41666667, 0.54237288, 0.45833333],\n",
       "       [0.38888889, 0.375     , 0.54237288, 0.5       ],\n",
       "       [0.52777778, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.22222222, 0.20833333, 0.33898305, 0.41666667],\n",
       "       [0.38888889, 0.33333333, 0.52542373, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.84745763, 1.        ],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.77777778, 0.41666667, 0.83050847, 0.83333333],\n",
       "       [0.55555556, 0.375     , 0.77966102, 0.70833333],\n",
       "       [0.61111111, 0.41666667, 0.81355932, 0.875     ],\n",
       "       [0.91666667, 0.41666667, 0.94915254, 0.83333333],\n",
       "       [0.16666667, 0.20833333, 0.59322034, 0.66666667],\n",
       "       [0.83333333, 0.375     , 0.89830508, 0.70833333],\n",
       "       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n",
       "       [0.80555556, 0.66666667, 0.86440678, 1.        ],\n",
       "       [0.61111111, 0.5       , 0.69491525, 0.79166667],\n",
       "       [0.58333333, 0.29166667, 0.72881356, 0.75      ],\n",
       "       [0.69444444, 0.41666667, 0.76271186, 0.83333333],\n",
       "       [0.38888889, 0.20833333, 0.6779661 , 0.79166667],\n",
       "       [0.41666667, 0.33333333, 0.69491525, 0.95833333],\n",
       "       [0.58333333, 0.5       , 0.72881356, 0.91666667],\n",
       "       [0.61111111, 0.41666667, 0.76271186, 0.70833333],\n",
       "       [0.94444444, 0.75      , 0.96610169, 0.875     ],\n",
       "       [0.94444444, 0.25      , 1.        , 0.91666667],\n",
       "       [0.47222222, 0.08333333, 0.6779661 , 0.58333333],\n",
       "       [0.72222222, 0.5       , 0.79661017, 0.91666667],\n",
       "       [0.36111111, 0.33333333, 0.66101695, 0.79166667],\n",
       "       [0.94444444, 0.33333333, 0.96610169, 0.79166667],\n",
       "       [0.55555556, 0.29166667, 0.66101695, 0.70833333],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 0.83333333],\n",
       "       [0.80555556, 0.5       , 0.84745763, 0.70833333],\n",
       "       [0.52777778, 0.33333333, 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.41666667, 0.66101695, 0.70833333],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.83333333],\n",
       "       [0.80555556, 0.41666667, 0.81355932, 0.625     ],\n",
       "       [0.86111111, 0.33333333, 0.86440678, 0.75      ],\n",
       "       [1.        , 0.75      , 0.91525424, 0.79166667],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.875     ],\n",
       "       [0.55555556, 0.33333333, 0.69491525, 0.58333333],\n",
       "       [0.5       , 0.25      , 0.77966102, 0.54166667],\n",
       "       [0.94444444, 0.41666667, 0.86440678, 0.91666667],\n",
       "       [0.55555556, 0.58333333, 0.77966102, 0.95833333],\n",
       "       [0.58333333, 0.45833333, 0.76271186, 0.70833333],\n",
       "       [0.47222222, 0.41666667, 0.6440678 , 0.70833333],\n",
       "       [0.72222222, 0.45833333, 0.74576271, 0.83333333],\n",
       "       [0.66666667, 0.45833333, 0.77966102, 0.95833333],\n",
       "       [0.72222222, 0.45833333, 0.69491525, 0.91666667],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.69444444, 0.5       , 0.83050847, 0.91666667],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 1.        ],\n",
       "       [0.66666667, 0.41666667, 0.71186441, 0.91666667],\n",
       "       [0.55555556, 0.20833333, 0.6779661 , 0.75      ],\n",
       "       [0.61111111, 0.41666667, 0.71186441, 0.79166667],\n",
       "       [0.52777778, 0.58333333, 0.74576271, 0.91666667],\n",
       "       [0.44444444, 0.41666667, 0.69491525, 0.70833333]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melakukan normalisasi \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rasyid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3989 - loss: 1.0521  \n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5224 - loss: 1.0160\n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6406 - loss: 0.9973 \n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6385 - loss: 0.9663 \n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6677 - loss: 0.9384 \n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6667 - loss: 0.9073 \n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6927 - loss: 0.8648 \n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6875 - loss: 0.8413 \n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6740 - loss: 0.8234 \n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6698 - loss: 0.8006 \n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6344 - loss: 0.7779 \n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6729 - loss: 0.7276 \n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6698 - loss: 0.7011 \n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6677 - loss: 0.6795 \n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6792 - loss: 0.6430 \n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6438 - loss: 0.6342 \n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7021 - loss: 0.5745 \n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6385 - loss: 0.5888 \n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7038 - loss: 0.5494\n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7111 - loss: 0.5193 \n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7093 - loss: 0.5112 \n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6930 - loss: 0.4965 \n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7790 - loss: 0.4744 \n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8127 - loss: 0.4788 \n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8543 - loss: 0.4333 \n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8980 - loss: 0.4277 \n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8939 - loss: 0.4133 \n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8751 - loss: 0.3980 \n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8720 - loss: 0.3946 \n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8731 - loss: 0.3779 \n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8852 - loss: 0.4045 \n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9490 - loss: 0.3610 \n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9511 - loss: 0.3513 \n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9449 - loss: 0.3365 \n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9476 - loss: 0.3444 \n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9351 - loss: 0.3517 \n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9362 - loss: 0.3476 \n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9428 - loss: 0.2965 \n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9521 - loss: 0.2957 \n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9459 - loss: 0.2843 \n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9549 - loss: 0.2866 \n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9362 - loss: 0.2868 \n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9570 - loss: 0.2655 \n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9546 - loss: 0.2550 \n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9723 - loss: 0.2359 \n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9639 - loss: 0.2370 \n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9660 - loss: 0.2141 \n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9785 - loss: 0.2106 \n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9754 - loss: 0.2036 \n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9518 - loss: 0.2091 \n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9487 - loss: 0.2028 \n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9698 - loss: 0.1855 \n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9702 - loss: 0.1740 \n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9729 - loss: 0.1733 \n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9507 - loss: 0.1761 \n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9698 - loss: 0.1701 \n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9514 - loss: 0.1670 \n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.1602 \n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9792 - loss: 0.1442 \n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9604 - loss: 0.1570 \n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9671 - loss: 0.1319 \n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9698 - loss: 0.1466 \n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9761 - loss: 0.1373 \n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9729 - loss: 0.1235 \n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9729 - loss: 0.1335 \n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9723 - loss: 0.1238 \n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9813 - loss: 0.1091 \n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9612 - loss: 0.1235 \n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9334 - loss: 0.1309 \n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9546 - loss: 0.1246 \n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9750 - loss: 0.1184 \n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.1180 \n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9761 - loss: 0.1106 \n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9729 - loss: 0.1038\n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9729 - loss: 0.1024 \n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9750 - loss: 0.1093 \n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9660 - loss: 0.1024 \n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9577 - loss: 0.1118 \n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9608 - loss: 0.1059 \n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.1010 \n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9667 - loss: 0.0963 \n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9698 - loss: 0.1037 \n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0861 \n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9608 - loss: 0.1047 \n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9604 - loss: 0.1089 \n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9792 - loss: 0.0781 \n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9729 - loss: 0.0908 \n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9604 - loss: 0.0945 \n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9754 - loss: 0.0732 \n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9729 - loss: 0.0865 \n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9542 - loss: 0.1077 \n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9639 - loss: 0.0792 \n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9546 - loss: 0.0968 \n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9761 - loss: 0.0774 \n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9698 - loss: 0.0889 \n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9546 - loss: 0.0962 \n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9743 - loss: 0.0718 \n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9775 - loss: 0.0682 \n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9691 - loss: 0.0847 \n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9698 - loss: 0.0860 \n"
     ]
    }
   ],
   "source": [
    "# membagi data train dan test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_scale, y, test_size=0.3)\n",
    "\n",
    "# model dengan 3 layer\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(4,)),\n",
    "    Dense(62, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# menentukan optimizer dan loss function \n",
    "model.compile(optimizer='Adam',\n",
    "              # tugas categorical crossentropy untuk evaluasi seberapa baik  model\n",
    "              # untuk memprediksi distribusi probabilitas kelas yang benar\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# melakuakn penampuangan kedalam objek hist(history )\n",
    "hist = model.fit(X_train, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9280 - loss: 0.1032  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07511703670024872, 0.9555555582046509]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluasi model \n",
    "model.evaluate(X_test, Y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot loss dan akurtasi trained model (visualisasi plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mencegah Overfitting dengan Dropout dan Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rasyid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(4,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### batch normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rasyid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(4,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0,5),\n",
    "    BatchNormalization(momentum=0.99),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimasi Pelatihan Menggunakan Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rasyid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.4318 - loss: 1.1550\n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6944 - loss: 0.7413\n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8637 - loss: 0.5206\n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8838 - loss: 0.4208\n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8796 - loss: 0.3614\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8349 - loss: 0.3441\n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8512 - loss: 0.3090\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9025 - loss: 0.2893\n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9317 - loss: 0.2596\n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9279 - loss: 0.2552\n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9723 - loss: 0.2053\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9844 - loss: 0.1657\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9546 - loss: 0.1857\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9438 - loss: 0.1938\n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9320 - loss: 0.1780\n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9636 - loss: 0.1584\n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9639 - loss: 0.1495\n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9608 - loss: 0.1452\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9393 - loss: 0.1567\n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9910 - loss: 0.1258\n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9719 - loss: 0.1261 \n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9639 - loss: 0.1224\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9570 - loss: 0.1257\n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.1559\n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9962 - loss: 0.1067\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9695 - loss: 0.1030\n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9518 - loss: 0.1548\n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9788 - loss: 0.0907\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9598 - loss: 0.1001\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9636 - loss: 0.1063\n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9636 - loss: 0.0993\n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9487 - loss: 0.1023\n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9698 - loss: 0.0978\n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9664 - loss: 0.0843\n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9487 - loss: 0.1264\n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9604 - loss: 0.0994\n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9712 - loss: 0.0884 \n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9813 - loss: 0.0907\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9695 - loss: 0.1118\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9792 - loss: 0.0820\n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9813 - loss: 0.0719\n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9639 - loss: 0.1203\n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9695 - loss: 0.0894\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9792 - loss: 0.0773\n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9528 - loss: 0.1007\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9539 - loss: 0.0913\n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9788 - loss: 0.0874\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0658\n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9566 - loss: 0.0937\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9788 - loss: 0.0876\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9788 - loss: 0.0776\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9698 - loss: 0.0798\n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9820 - loss: 0.0710\n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9702 - loss: 0.0792\n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9636 - loss: 0.0870\n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9851 - loss: 0.0644 \n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9393 - loss: 0.1265 \n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9632 - loss: 0.0758\n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9761 - loss: 0.0822\n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9847 - loss: 0.0876 \n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9729 - loss: 0.0824\n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9577 - loss: 0.1004\n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9490 - loss: 0.0949 \n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0535\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0598\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9782 - loss: 0.0792\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9698 - loss: 0.0672\n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9604 - loss: 0.0663\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9202 - loss: 0.1386\n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9771 - loss: 0.0768\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9847 - loss: 0.0671\n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9851 - loss: 0.0683\n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9719 - loss: 0.0569\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9851 - loss: 0.0677\n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9820 - loss: 0.0821\n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9636 - loss: 0.0926 \n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9761 - loss: 0.0725 \n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9691 - loss: 0.0585\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0500\n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9910 - loss: 0.0484\n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.0735\n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9962 - loss: 0.0583\n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9757 - loss: 0.0645\n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 0.0524\n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9723 - loss: 0.0955\n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0642\n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9667 - loss: 0.0581\n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9653 - loss: 0.0670 \n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9604 - loss: 0.0850\n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9698 - loss: 0.0745\n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9792 - loss: 0.0565\n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9844 - loss: 0.0538\n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9757 - loss: 0.0610\n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.0548\n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9695 - loss: 0.0701\n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9820 - loss: 0.0669\n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9757 - loss: 0.0862\n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9566 - loss: 0.0933\n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9788 - loss: 0.0620\n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9788 - loss: 0.0693\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "import tensorflow as tf\n",
    "df = pd.read_csv('https://drive.google.com/uc?id=1roJ83AbgzDcvRr0Gwud0BmdUQx-oSG-w')\n",
    "df = df.drop(columns='Id')\n",
    "category = pd.get_dummies(df.Species, dtype=int)\n",
    "new_df = pd.concat([df, category], axis=1)\n",
    "new_df = new_df.drop(columns='Species')\n",
    "dataset = new_df.values\n",
    "# Pilih 4 kolom pertama untuk dijadikan sebagai atribut\n",
    "X = dataset[:,0:4]\n",
    "# Pilih 3 kolom terakhir sebagai label\n",
    "y = dataset[:,4:7]\n",
    "# Normalisasi\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "X_scale\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scale, y, test_size=0.3)\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "model = Sequential([\n",
    "                    Dense(64, activation='relu', input_shape=(4,)),\n",
    "                    Dense(64, activation='relu'),\n",
    "                    Dropout(0,5),\n",
    "                    BatchNormalization(momentum=0.99),\n",
    "                    Dense(3, activation='softmax')])\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "hist = model.fit(X_train, Y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0770\n",
      " akurasi sudah mencapai 90%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9851 - loss: 0.0927\n"
     ]
    }
   ],
   "source": [
    "# membuat clas callback\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.9):\n",
    "            print(\"\\n akurasi sudah mencapai 90%\")\n",
    "            self.model.stop_training = True\n",
    "callbacks=myCallback()\n",
    "\n",
    "# menambah parameter\n",
    "hist = model.fit(X_train, Y_train, epochs=100, callbacks = [callbacks])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menggunakan Dataset dari TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "import tensorflow as tf\n",
    "\n",
    "# menampung dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# melakukan pembagian dataset\n",
    "(gambar_latih, label_latih), (gambar_testing, label_testing) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# menampillkan label\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(linewidth=200)\n",
    "plt.imshow(gambar_latih[0])\n",
    "print(label_latih[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rasyid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1117 - loss: 2.3016\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1111 - loss: 2.3013\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1112 - loss: 2.3000\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1105 - loss: 2.2967\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1292 - loss: 2.2890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e2a227f710>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melakukan normalisasi data\n",
    "gambar_latih  = gambar_latih / 255.0\n",
    "gambar_testing = gambar_testing / 255.0\n",
    "\n",
    "# menggunakna 3 layer untuk mengubah input matriks 2d menjadi 1d\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# menentukan optimizer\n",
    "model.compile(optimizer=tf._optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(gambar_latih, label_latih, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat Model Menggunakan TensorFlow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow_datasets) (2.1.0)\n",
      "Collecting dm-tree (from tensorflow_datasets)\n",
      "  Downloading dm_tree-0.1.9-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: etils>=1.9.1 in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (1.11.0)\n",
      "Collecting immutabledict (from tensorflow_datasets)\n",
      "  Downloading immutabledict-4.2.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow_datasets) (2.0.2)\n",
      "Collecting promise (from tensorflow_datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow_datasets) (5.29.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\rasyid\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow_datasets) (6.0.0)\n",
      "Collecting pyarrow (from tensorflow_datasets)\n",
      "  Using cached pyarrow-19.0.1-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow_datasets) (2.32.3)\n",
      "Collecting simple_parsing (from tensorflow_datasets)\n",
      "  Downloading simple_parsing-0.1.7-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
      "  Downloading tensorflow_metadata-1.16.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: termcolor in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow_datasets) (2.5.0)\n",
      "Collecting toml (from tensorflow_datasets)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow_datasets) (4.67.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow_datasets) (1.17.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (2024.12.0)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (6.5.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (4.12.2)\n",
      "Requirement already satisfied: zipp in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rasyid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2024.12.14)\n",
      "Collecting attrs>=18.2.0 (from dm-tree->tensorflow_datasets)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: six in c:\\users\\rasyid\\appdata\\roaming\\python\\python312\\site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from simple_parsing->tensorflow_datasets)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.56.4 (from tensorflow-metadata->tensorflow_datasets)\n",
      "  Downloading googleapis_common_protos-1.69.1-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\rasyid\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->tensorflow_datasets) (0.4.6)\n",
      "Downloading tensorflow_datasets-4.9.8-py3-none-any.whl (5.3 MB)\n",
      "   ---------------------------------------- 0.0/5.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/5.3 MB 2.6 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.2/5.3 MB 2.4 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.3/5.3 MB 2.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.4/5.3 MB 2.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.5/5.3 MB 2.2 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.6/5.3 MB 2.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.7/5.3 MB 2.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.8/5.3 MB 2.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.9/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.0/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.1/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.2/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.3/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.4/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.5/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.6/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.8/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.8/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 1.9/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.1/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.2/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.3/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 2.4/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.4/5.3 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.7/5.3 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 2.8/5.3 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.0/5.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.2/5.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.3/5.3 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.5/5.3 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.6/5.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.8/5.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.9/5.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.1/5.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.2/5.3 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.4/5.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.5/5.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.7/5.3 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.9/5.3 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.0/5.3 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.2/5.3 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.3/5.3 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.3/5.3 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading dm_tree-0.1.9-cp312-cp312-win_amd64.whl (102 kB)\n",
      "   ---------------------------------------- 0.0/102.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 102.0/102.0 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading immutabledict-4.2.1-py3-none-any.whl (4.7 kB)\n",
      "Using cached pyarrow-19.0.1-cp312-cp312-win_amd64.whl (25.3 MB)\n",
      "Downloading simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n",
      "   ---------------------------------------- 0.0/112.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 112.8/112.8 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading tensorflow_metadata-1.16.1-py3-none-any.whl (28 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "   ---------------------------------------- 0.0/63.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 63.8/63.8 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading googleapis_common_protos-1.69.1-py2.py3-none-any.whl (293 kB)\n",
      "   ---------------------------------------- 0.0/293.2 kB ? eta -:--:--\n",
      "   ---------------------------------------  286.7/293.2 kB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 293.2/293.2 kB 6.0 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21613 sha256=646267004ab6b299cbb06dbeb2d90238ac85892f39a3f6ce338267d21882a043\n",
      "  Stored in directory: c:\\users\\rasyid\\appdata\\local\\pip\\cache\\wheels\\e7\\e6\\28\\864bdfee5339dbd6ddcb5a186286a8e217648ec198bdf0097d\n",
      "Successfully built promise\n",
      "Installing collected packages: toml, pyarrow, promise, immutabledict, googleapis-common-protos, docstring-parser, attrs, tensorflow-metadata, simple_parsing, dm-tree, tensorflow_datasets\n",
      "Successfully installed attrs-25.3.0 dm-tree-0.1.9 docstring-parser-0.16 googleapis-common-protos-1.69.1 immutabledict-4.2.1 promise-2.3 pyarrow-19.0.1 simple_parsing-0.1.7 tensorflow-metadata-1.16.1 tensorflow_datasets-4.9.8 toml-0.10.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tfds.exe is installed in 'c:\\Users\\rasyid\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning',\n",
       " 'accentdb',\n",
       " 'aeslc',\n",
       " 'aflw2k3d',\n",
       " 'ag_news_subset',\n",
       " 'ai2_arc',\n",
       " 'ai2_arc_with_ir',\n",
       " 'ai2dcaption',\n",
       " 'aloha_mobile',\n",
       " 'amazon_us_reviews',\n",
       " 'anli',\n",
       " 'answer_equivalence',\n",
       " 'arc',\n",
       " 'asimov_dilemmas_auto_val',\n",
       " 'asimov_dilemmas_scifi_train',\n",
       " 'asimov_dilemmas_scifi_val',\n",
       " 'asimov_injury_val',\n",
       " 'asimov_multimodal_auto_val',\n",
       " 'asimov_multimodal_manual_val',\n",
       " 'asqa',\n",
       " 'asset',\n",
       " 'assin2',\n",
       " 'asu_table_top_converted_externally_to_rlds',\n",
       " 'austin_buds_dataset_converted_externally_to_rlds',\n",
       " 'austin_sailor_dataset_converted_externally_to_rlds',\n",
       " 'austin_sirius_dataset_converted_externally_to_rlds',\n",
       " 'bair_robot_pushing_small',\n",
       " 'bc_z',\n",
       " 'bccd',\n",
       " 'beans',\n",
       " 'bee_dataset',\n",
       " 'beir',\n",
       " 'berkeley_autolab_ur5',\n",
       " 'berkeley_cable_routing',\n",
       " 'berkeley_fanuc_manipulation',\n",
       " 'berkeley_gnm_cory_hall',\n",
       " 'berkeley_gnm_recon',\n",
       " 'berkeley_gnm_sac_son',\n",
       " 'berkeley_mvp_converted_externally_to_rlds',\n",
       " 'berkeley_rpt_converted_externally_to_rlds',\n",
       " 'big_patent',\n",
       " 'bigearthnet',\n",
       " 'billsum',\n",
       " 'binarized_mnist',\n",
       " 'binary_alpha_digits',\n",
       " 'ble_wind_field',\n",
       " 'blimp',\n",
       " 'booksum',\n",
       " 'bool_q',\n",
       " 'bot_adversarial_dialogue',\n",
       " 'bridge',\n",
       " 'bridge_data_msr',\n",
       " 'bucc',\n",
       " 'c4',\n",
       " 'c4_wsrs',\n",
       " 'caltech101',\n",
       " 'caltech_birds2010',\n",
       " 'caltech_birds2011',\n",
       " 'cardiotox',\n",
       " 'cars196',\n",
       " 'cassava',\n",
       " 'cats_vs_dogs',\n",
       " 'celeb_a',\n",
       " 'celeb_a_hq',\n",
       " 'cfq',\n",
       " 'cherry_blossoms',\n",
       " 'chexpert',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'cifar100_n',\n",
       " 'cifar10_1',\n",
       " 'cifar10_corrupted',\n",
       " 'cifar10_h',\n",
       " 'cifar10_n',\n",
       " 'citrus_leaves',\n",
       " 'cityscapes',\n",
       " 'civil_comments',\n",
       " 'clevr',\n",
       " 'clic',\n",
       " 'clinc_oos',\n",
       " 'cmaterdb',\n",
       " 'cmu_franka_exploration_dataset_converted_externally_to_rlds',\n",
       " 'cmu_play_fusion',\n",
       " 'cmu_stretch',\n",
       " 'cnn_dailymail',\n",
       " 'coco',\n",
       " 'coco_captions',\n",
       " 'coil100',\n",
       " 'colorectal_histology',\n",
       " 'colorectal_histology_large',\n",
       " 'columbia_cairlab_pusht_real',\n",
       " 'common_voice',\n",
       " 'conll2002',\n",
       " 'conll2003',\n",
       " 'conq_hose_manipulation',\n",
       " 'controlled_noisy_web_labels',\n",
       " 'coqa',\n",
       " 'corr2cause',\n",
       " 'cos_e',\n",
       " 'cosmos_qa',\n",
       " 'covid19',\n",
       " 'covid19sum',\n",
       " 'crema_d',\n",
       " 'criteo',\n",
       " 'cs_restaurants',\n",
       " 'curated_breast_imaging_ddsm',\n",
       " 'cycle_gan',\n",
       " 'd4rl_adroit_door',\n",
       " 'd4rl_adroit_hammer',\n",
       " 'd4rl_adroit_pen',\n",
       " 'd4rl_adroit_relocate',\n",
       " 'd4rl_antmaze',\n",
       " 'd4rl_mujoco_ant',\n",
       " 'd4rl_mujoco_halfcheetah',\n",
       " 'd4rl_mujoco_hopper',\n",
       " 'd4rl_mujoco_walker2d',\n",
       " 'dart',\n",
       " 'databricks_dolly',\n",
       " 'davis',\n",
       " 'deep1b',\n",
       " 'deep_weeds',\n",
       " 'definite_pronoun_resolution',\n",
       " 'dementiabank',\n",
       " 'diabetic_retinopathy_detection',\n",
       " 'diamonds',\n",
       " 'dices',\n",
       " 'div2k',\n",
       " 'dlr_edan_shared_control_converted_externally_to_rlds',\n",
       " 'dlr_sara_grid_clamp_converted_externally_to_rlds',\n",
       " 'dlr_sara_pour_converted_externally_to_rlds',\n",
       " 'dmlab',\n",
       " 'dobbe',\n",
       " 'doc_nli',\n",
       " 'dolma',\n",
       " 'dolphin_number_word',\n",
       " 'domainnet',\n",
       " 'downsampled_imagenet',\n",
       " 'drop',\n",
       " 'dsprites',\n",
       " 'dtd',\n",
       " 'duke_ultrasound',\n",
       " 'e2e_cleaned',\n",
       " 'efron_morris75',\n",
       " 'emnist',\n",
       " 'eraser_multi_rc',\n",
       " 'esnli',\n",
       " 'eth_agent_affordances',\n",
       " 'eurosat',\n",
       " 'fashion_mnist',\n",
       " 'flic',\n",
       " 'flores',\n",
       " 'fmb',\n",
       " 'food101',\n",
       " 'forest_fires',\n",
       " 'fractal20220817_data',\n",
       " 'fuss',\n",
       " 'gap',\n",
       " 'geirhos_conflict_stimuli',\n",
       " 'gem',\n",
       " 'genomics_ood',\n",
       " 'german_credit_numeric',\n",
       " 'gigaword',\n",
       " 'glove100_angular',\n",
       " 'glue',\n",
       " 'goemotions',\n",
       " 'gov_report',\n",
       " 'gpt3',\n",
       " 'gref',\n",
       " 'groove',\n",
       " 'grounded_scan',\n",
       " 'gsm8k',\n",
       " 'gtzan',\n",
       " 'gtzan_music_speech',\n",
       " 'hellaswag',\n",
       " 'higgs',\n",
       " 'hillstrom',\n",
       " 'horses_or_humans',\n",
       " 'howell',\n",
       " 'i_naturalist2017',\n",
       " 'i_naturalist2018',\n",
       " 'i_naturalist2021',\n",
       " 'iamlab_cmu_pickup_insert_converted_externally_to_rlds',\n",
       " 'imagenet2012',\n",
       " 'imagenet2012_corrupted',\n",
       " 'imagenet2012_fewshot',\n",
       " 'imagenet2012_multilabel',\n",
       " 'imagenet2012_real',\n",
       " 'imagenet2012_subset',\n",
       " 'imagenet_a',\n",
       " 'imagenet_lt',\n",
       " 'imagenet_pi',\n",
       " 'imagenet_r',\n",
       " 'imagenet_resized',\n",
       " 'imagenet_sketch',\n",
       " 'imagenet_v2',\n",
       " 'imagenette',\n",
       " 'imagewang',\n",
       " 'imdb_reviews',\n",
       " 'imperialcollege_sawyer_wrist_cam',\n",
       " 'io_ai_tech',\n",
       " 'irc_disentanglement',\n",
       " 'iris',\n",
       " 'istella',\n",
       " 'jaco_play',\n",
       " 'kaist_nonprehensile_converted_externally_to_rlds',\n",
       " 'kddcup99',\n",
       " 'kitti',\n",
       " 'kmnist',\n",
       " 'kuka',\n",
       " 'laion400m',\n",
       " 'lambada',\n",
       " 'lfw',\n",
       " 'librispeech',\n",
       " 'librispeech_lm',\n",
       " 'libritts',\n",
       " 'ljspeech',\n",
       " 'lm1b',\n",
       " 'locomotion',\n",
       " 'lost_and_found',\n",
       " 'lsun',\n",
       " 'lvis',\n",
       " 'malaria',\n",
       " 'maniskill_dataset_converted_externally_to_rlds',\n",
       " 'math_dataset',\n",
       " 'math_qa',\n",
       " 'mctaco',\n",
       " 'media_sum',\n",
       " 'mimic_play',\n",
       " 'mlqa',\n",
       " 'mnist',\n",
       " 'mnist_corrupted',\n",
       " 'movie_lens',\n",
       " 'movie_rationales',\n",
       " 'movielens',\n",
       " 'moving_mnist',\n",
       " 'mrqa',\n",
       " 'mslr_web',\n",
       " 'mt_opt',\n",
       " 'mtnt',\n",
       " 'multi_news',\n",
       " 'multi_nli',\n",
       " 'multi_nli_mismatch',\n",
       " 'natural_instructions',\n",
       " 'natural_questions',\n",
       " 'natural_questions_open',\n",
       " 'newsroom',\n",
       " 'nsynth',\n",
       " 'nyu_depth_v2',\n",
       " 'nyu_door_opening_surprising_effectiveness',\n",
       " 'nyu_franka_play_dataset_converted_externally_to_rlds',\n",
       " 'nyu_rot_dataset_converted_externally_to_rlds',\n",
       " 'ogbg_molpcba',\n",
       " 'omniglot',\n",
       " 'open_images_challenge2019_detection',\n",
       " 'open_images_v4',\n",
       " 'openbookqa',\n",
       " 'opinion_abstracts',\n",
       " 'opinosis',\n",
       " 'opus',\n",
       " 'oxford_flowers102',\n",
       " 'oxford_iiit_pet',\n",
       " 'para_crawl',\n",
       " 'pass',\n",
       " 'patch_camelyon',\n",
       " 'paws_wiki',\n",
       " 'paws_x_wiki',\n",
       " 'penguins',\n",
       " 'pet_finder',\n",
       " 'pg19',\n",
       " 'piqa',\n",
       " 'places365_small',\n",
       " 'placesfull',\n",
       " 'plant_leaves',\n",
       " 'plant_village',\n",
       " 'plantae_k',\n",
       " 'plex_robosuite',\n",
       " 'pneumonia_mnist',\n",
       " 'protein_net',\n",
       " 'q_re_cc',\n",
       " 'qa4mre',\n",
       " 'qasc',\n",
       " 'qm9',\n",
       " 'quac',\n",
       " 'quality',\n",
       " 'quickdraw_bitmap',\n",
       " 'race',\n",
       " 'radon',\n",
       " 'real_toxicity_prompts',\n",
       " 'reddit',\n",
       " 'reddit_disentanglement',\n",
       " 'reddit_tifu',\n",
       " 'ref_coco',\n",
       " 'resisc45',\n",
       " 'rlu_atari',\n",
       " 'rlu_atari_checkpoints',\n",
       " 'rlu_atari_checkpoints_ordered',\n",
       " 'rlu_control_suite',\n",
       " 'rlu_dmlab_explore_object_rewards_few',\n",
       " 'rlu_dmlab_explore_object_rewards_many',\n",
       " 'rlu_dmlab_rooms_select_nonmatching_object',\n",
       " 'rlu_dmlab_rooms_watermaze',\n",
       " 'rlu_dmlab_seekavoid_arena01',\n",
       " 'rlu_locomotion',\n",
       " 'rlu_rwrl',\n",
       " 'robo_set',\n",
       " 'robomimic_mg',\n",
       " 'robomimic_mh',\n",
       " 'robomimic_ph',\n",
       " 'robonet',\n",
       " 'robosuite_panda_pick_place_can',\n",
       " 'roboturk',\n",
       " 'rock_paper_scissors',\n",
       " 'rock_you',\n",
       " 's3o4d',\n",
       " 'salient_span_wikipedia',\n",
       " 'samsum',\n",
       " 'savee',\n",
       " 'scan',\n",
       " 'scene_parse150',\n",
       " 'schema_guided_dialogue',\n",
       " 'sci_tail',\n",
       " 'scicite',\n",
       " 'scientific_papers',\n",
       " 'scrolls',\n",
       " 'segment_anything',\n",
       " 'sentiment140',\n",
       " 'shapes3d',\n",
       " 'sift1m',\n",
       " 'simpte',\n",
       " 'siscore',\n",
       " 'smallnorb',\n",
       " 'smart_buildings',\n",
       " 'smartwatch_gestures',\n",
       " 'snli',\n",
       " 'so2sat',\n",
       " 'speech_commands',\n",
       " 'spoc_robot',\n",
       " 'spoken_digit',\n",
       " 'squad',\n",
       " 'squad_question_generation',\n",
       " 'stanford_dogs',\n",
       " 'stanford_hydra_dataset_converted_externally_to_rlds',\n",
       " 'stanford_kuka_multimodal_dataset_converted_externally_to_rlds',\n",
       " 'stanford_mask_vit_converted_externally_to_rlds',\n",
       " 'stanford_online_products',\n",
       " 'stanford_robocook_converted_externally_to_rlds',\n",
       " 'star_cfq',\n",
       " 'starcraft_video',\n",
       " 'stl10',\n",
       " 'story_cloze',\n",
       " 'summscreen',\n",
       " 'sun397',\n",
       " 'super_glue',\n",
       " 'svhn_cropped',\n",
       " 'symmetric_solids',\n",
       " 'taco_play',\n",
       " 'tao',\n",
       " 'tatoeba',\n",
       " 'ted_hrlr_translate',\n",
       " 'ted_multi_translate',\n",
       " 'tedlium',\n",
       " 'tf_flowers',\n",
       " 'the300w_lp',\n",
       " 'tidybot',\n",
       " 'tiny_shakespeare',\n",
       " 'titanic',\n",
       " 'tokyo_u_lsmo_converted_externally_to_rlds',\n",
       " 'toto',\n",
       " 'trec',\n",
       " 'trivia_qa',\n",
       " 'tydi_qa',\n",
       " 'uc_merced',\n",
       " 'ucf101',\n",
       " 'ucsd_kitchen_dataset_converted_externally_to_rlds',\n",
       " 'ucsd_pick_and_place_dataset_converted_externally_to_rlds',\n",
       " 'uiuc_d3field',\n",
       " 'unified_qa',\n",
       " 'universal_dependencies',\n",
       " 'unnatural_instructions',\n",
       " 'usc_cloth_sim_converted_externally_to_rlds',\n",
       " 'user_libri_audio',\n",
       " 'user_libri_text',\n",
       " 'utaustin_mutex',\n",
       " 'utokyo_pr2_opening_fridge_converted_externally_to_rlds',\n",
       " 'utokyo_pr2_tabletop_manipulation_converted_externally_to_rlds',\n",
       " 'utokyo_saytap_converted_externally_to_rlds',\n",
       " 'utokyo_xarm_bimanual_converted_externally_to_rlds',\n",
       " 'utokyo_xarm_pick_and_place_converted_externally_to_rlds',\n",
       " 'vctk',\n",
       " 'vima_converted_externally_to_rlds',\n",
       " 'viola',\n",
       " 'visual_domain_decathlon',\n",
       " 'voc',\n",
       " 'voxceleb',\n",
       " 'voxforge',\n",
       " 'wake_vision',\n",
       " 'waymo_open_dataset',\n",
       " 'web_graph',\n",
       " 'web_nlg',\n",
       " 'web_questions',\n",
       " 'webvid',\n",
       " 'wider_face',\n",
       " 'wiki40b',\n",
       " 'wiki_auto',\n",
       " 'wiki_bio',\n",
       " 'wiki_dialog',\n",
       " 'wiki_table_questions',\n",
       " 'wiki_table_text',\n",
       " 'wikiann',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wikipedia_toxicity_subtypes',\n",
       " 'wine_quality',\n",
       " 'winogrande',\n",
       " 'wit',\n",
       " 'wit_kaggle',\n",
       " 'wmt13_translate',\n",
       " 'wmt14_translate',\n",
       " 'wmt15_translate',\n",
       " 'wmt16_translate',\n",
       " 'wmt17_translate',\n",
       " 'wmt18_translate',\n",
       " 'wmt19_translate',\n",
       " 'wmt_t2t_translate',\n",
       " 'wmt_translate',\n",
       " 'wordnet',\n",
       " 'wsc273',\n",
       " 'xnli',\n",
       " 'xquad',\n",
       " 'xsum',\n",
       " 'xtreme_pawsx',\n",
       " 'xtreme_pos',\n",
       " 'xtreme_s',\n",
       " 'xtreme_xnli',\n",
       " 'yahoo_ltrc',\n",
       " 'yelp_polarity_reviews',\n",
       " 'yes_no',\n",
       " 'youtube_vis']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Variant folder C:\\Users\\rasyid\\tensorflow_datasets\\mnist\\3.0.1 has no dataset_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\rasyid\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rasyid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  1.91 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.54 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.36 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.10 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.02 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.43 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.32 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.23 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.05 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  3.57 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  3.49 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.78 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.14 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  1.65 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  1.29 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:02<00:00,  1.06 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:03<00:01,  1.05s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:03<00:01,  1.15s/ url]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:03<00:01,  1.25s/ url]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:03<00:00,  1.03 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:04<00:00,  1.03 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:04<00:00,  1.03 url/s]\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:04<00:00,  1.10s/ file]\n",
      "Dl Size...: 100%|██████████| 10/10 [00:04<00:00,  2.27 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:04<00:00,  1.10s/ url]\n",
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\rasyid\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "ds = tfds.load('mnist', split='train', shuffle_files=True)\n",
    "assert isinstance(ds, tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fungsi load() memungkinkan Anda untuk menggunakan dataset yang telah disediakan oleh TensorFlow Datasets. \n",
    "- Parameter pertama ('mnist') menunjukkan nama dataset yang ingin dimuat. \n",
    "- Parameter kedua ('split='train'') menunjukkan bahwa kita hanya memuat bagian pelatihan dari dataset MNIST. \n",
    "- Parameter ketiga ('shuffle_files=True') mengindikasikan bahwa file-file dataset akan diacak sebelum dimuat, sehingga urutan data tidak akan tetap sama setiap kali dataset dimuat ulang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rasyid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1079: The name tf.data.get_output_shapes is deprecated. Please use tf.compat.v1.data.get_output_shapes instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rasyid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1079: The name tf.data.get_output_shapes is deprecated. Please use tf.compat.v1.data.get_output_shapes instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tfds.as_numpy(tfds.load('mnist',\n",
    "              split = ['train', 'test'],\n",
    "              batch_size=-1,\n",
    "              as_supervised=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rasyid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(128,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menggukana 3 argumen untk melakukan compile model yang dibangun\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - accuracy: 0.8446 - loss: 0.8861\n",
      "Epoch 2/5\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.9762 - loss: 0.0835\n",
      "Epoch 3/5\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.9816 - loss: 0.0638\n",
      "Epoch 4/5\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.9858 - loss: 0.0531\n",
      "Epoch 5/5\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.9870 - loss: 0.0477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e2a842fc50>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, batch_size=50, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 6ms/step - accuracy: 0.9876 - loss: 0.0675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06861475110054016, 0.9861999750137329]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melakuakn evaluasi \n",
    "model.evaluate(test_images, test_labels, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penggunaan Batch Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rasyid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)), \n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8789 - loss: 0.4270\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9642 - loss: 0.1220\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0798\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9828 - loss: 0.0564\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9881 - loss: 0.0410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e2aaae86e0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, training_labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0262\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9955 - loss: 0.0190\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0170\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0144\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e2a842ff50>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, training_labels, batch_size=128, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
